# Rider AI Assistant Fake Local LM Studio Proxy OpenRouter Server

This repository contains a Go-based streaming chat API server. It uses the [Gin](https://github.com/gin-gonic/gin) framework for HTTP routing and the [go-openai](https://github.com/sashabaranov/go-openai) client library to interact with the OpenRouter API.  
**Note:** This code and documentation were generated by an AI.

## Features

- **Model Listing Endpoint:**  
  Provides a list of available models on two routes:
    - `GET /v1/models`
    - `GET /api/v0/models`

  The response includes details such as model ID, type, publisher, and context length.

- **Streaming Chat Endpoint:**  
  Implements a streaming chat endpoint on the following routes:
    - `POST /v1/chat/completions`
    - `POST /api/v0/chat/completions`

  The handler:
    - Accepts a chat request containing model details, messages, and other options.
    - Uses the OpenRouter API to stream chat responses.
    - Buffers the last chunk of the response stream. If the final chunk doesn't include content in the `delta` field, it modifies it by setting the `delta` to an empty object and the `finish_reason` to `"stop"`.
    - Sends each chunk as a Server-Sent Event (SSE) to the client.
    - Finishes the stream by sending a `data: [DONE]` message.

## Requirements

- Go 1.16+
- Set the environment variable `OPENROUTER_API_KEY` with your API key.

`Linux/macOS:`
`export OPENROUTER_API_KEY=your_api_key_here`

`Windows CMD:`
`set OPENROUTER_API_KEY=your_api_key_here`

`Windows PowerShell:`
`$env:OPENROUTER_API_KEY="your_api_key_here"`


- Install dependencies with:
  ```bash
  go get -u github.com/gin-gonic/gin
  go get -u github.com/sashabaranov/go-openai
